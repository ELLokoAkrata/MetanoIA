# Proceso de Desarrollo del Proyecto

## 2025-05-09: Correcci√≥n de error de importaci√≥n

### Problema Identificado
Se detect√≥ un error en el archivo `chat_bot.py` donde se intentaba utilizar el m√≥dulo `os` sin haberlo importado previamente, lo que generaba el siguiente error:

```
NameError: name 'os' is not defined
```

### Soluci√≥n Implementada
Se agreg√≥ la importaci√≥n del m√≥dulo `os` al principio del archivo:

```python
import os
import streamlit as st
from groq import Groq
```

### Resultado
El c√≥digo ahora puede acceder correctamente a las variables de entorno para obtener la clave API de Groq.

## 2025-05-09: Implementaci√≥n de interfaz de chat completa

### Tarea Realizada
Se ha implementado una interfaz de chat completa con las siguientes caracter√≠sticas:

- Barra lateral configurable para seleccionar modelos y par√°metros
- Soporte para m√∫ltiples modelos de Groq (DeepSeek, Meta Llama, Qwen)
- Configuraci√≥n de par√°metros como temperatura y m√°ximo de tokens
- Personalizaci√≥n del system prompt
- Interfaz de chat moderna usando `st.chat_message` y `st.chat_input`
- Streaming de respuestas en tiempo real
- Persistencia de estado usando `st.session_state`
- Cach√© de respuestas usando `@st.cache_data`
- Estilo personalizado con CSS embebido

### C√≥digo Implementado
Se ha reescrito completamente el archivo `chat_bot.py` para incluir todas estas funcionalidades, siguiendo las mejores pr√°cticas de Streamlit y manteniendo un c√≥digo limpio y bien estructurado.

### Resultado
Ahora la aplicaci√≥n cuenta con una interfaz completa y funcional que permite interactuar con diferentes modelos de lenguaje a trav√©s de la API de Groq, con una experiencia de usuario mejorada.

## 2025-05-09: Mejora de la interfaz con tema "Fresh Tech"

### Tarea Realizada
Se ha implementado un dise√±o moderno con estilo "Fresh Tech" para la interfaz del chatbot:

- Gradientes modernos para el fondo y elementos de la interfaz
- Efectos de vidrio (glassmorphism) en los contenedores
- Colores vibrantes pero no agresivos
- Detalles de ne√≥n en botones y bordes
- Mejor contraste y legibilidad

### C√≥digo Implementado
Se ha modificado el CSS personalizado para implementar un tema oscuro con efectos modernos y tecnol√≥gicos.

### Resultado
La interfaz ahora tiene un aspecto m√°s moderno y tecnol√≥gico, con mejor legibilidad y experiencia de usuario.

## 2025-05-09: Implementaci√≥n de sistema de registro y soluci√≥n de problemas con cambio de modelo

### Problemas Identificados
1. Al cambiar de modelo en la barra lateral, no se aplicaba correctamente el cambio
2. No hab√≠a forma de saber qu√© modelo hab√≠a generado cada respuesta
3. No se registraba informaci√≥n detallada sobre las llamadas a la API

### Soluciones Implementadas
1. **Sistema de registro completo**:
   - Se agreg√≥ un sistema de logging que muestra informaci√≥n detallada en la terminal
   - Se registran cambios de modelo, llamadas a la API, tiempos de respuesta y errores

2. **Correcci√≥n del cambio de modelo**:
   - Se modific√≥ la forma en que se selecciona y aplica el cambio de modelo
   - Se fuerza una recarga de la aplicaci√≥n cuando cambia el modelo
   - Se usa una clave √∫nica para el widget de selecci√≥n

3. **Seguimiento del modelo usado**:
   - Se guarda informaci√≥n sobre qu√© modelo gener√≥ cada respuesta
   - Se muestra esta informaci√≥n en la interfaz
   - Se filtran los campos personalizados antes de enviar mensajes a la API

### C√≥digo Implementado
Se han realizado m√∫ltiples modificaciones al c√≥digo para implementar estas mejoras, incluyendo:

```python
# Sistema de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger("psycho-bot")

# Filtrado de campos personalizados para la API
api_messages = []
for msg in st.session_state.messages:
    if msg["role"] in ["user", "assistant"]:
        api_messages.append({"role": msg["role"], "content": msg["content"]})
```

### Resultado
- El cambio de modelo ahora funciona correctamente
- Se muestra qu√© modelo gener√≥ cada respuesta
- Se mantiene el contexto de la conversaci√≥n al cambiar entre modelos
- Se registra informaci√≥n detallada en la terminal para facilitar la depuraci√≥n

## 2025-05-09: Implementaci√≥n de limitaci√≥n din√°mica del contexto

### Problema Identificado
Al acumular muchos mensajes en una conversaci√≥n, se excede el l√≠mite de tokens por minuto (TPM) de la API de Groq, especialmente con los modelos Llama, generando el siguiente error:

```
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `meta-llama/llama-4-maverick-17b-128e-instruct`... Limit 6000, Requested 6029...', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
```

### Soluci√≥n Implementada
Se ha implementado un sistema de limitaci√≥n din√°mica del contexto que ajusta autom√°ticamente la cantidad de mensajes enviados a la API seg√∫n el modelo utilizado:

1. **Limitaci√≥n por modelo**:
   - Se establece un l√≠mite de mensajes predeterminado de 10
   - Para modelos Llama-4-Maverick, se reduce a 5 mensajes
   - Para modelos Llama-4-Scout, se reduce a 6 mensajes

2. **Selecci√≥n de mensajes recientes**:
   - Se seleccionan solo los mensajes m√°s recientes dentro del l√≠mite establecido
   - Se mantiene siempre el mensaje del sistema y el √∫ltimo mensaje del usuario

### C√≥digo Implementado
```python
# Obtener el n√∫mero m√°ximo de mensajes a incluir seg√∫n el modelo
max_context_messages = 10  # Valor predeterminado

# Ajustar el contexto seg√∫n el modelo para evitar errores de l√≠mite de tokens
if "llama-4-maverick" in current_model:
    max_context_messages = 5  # Limitar m√°s para modelos que tienen l√≠mites m√°s estrictos
elif "llama-4-scout" in current_model:
    max_context_messages = 6

# Registrar el l√≠mite de contexto aplicado
logger.info(f"Limitando contexto a {max_context_messages} mensajes para el modelo {current_model}")

# A√±adir mensajes del historial filtrando campos personalizados y limitando la cantidad
# Tomamos solo los mensajes m√°s recientes para no exceder los l√≠mites
recent_messages = st.session_state.messages[-max_context_messages:] if len(st.session_state.messages) > max_context_messages else st.session_state.messages
```

### Resultado
- La aplicaci√≥n ahora puede manejar conversaciones largas sin exceder los l√≠mites de tokens
- Se adapta autom√°ticamente a los diferentes l√≠mites de cada modelo
- Se mantiene la experiencia de usuario al conservar el contexto m√°s reciente
- Se registra en el log qu√© limitaci√≥n se est√° aplicando para cada modelo

## 2025-05-09: Modularizaci√≥n del c√≥digo y renombramiento a MetanoIA

### Tarea Realizada
Se ha realizado una completa modularizaci√≥n del c√≥digo del chatbot, reorganiz√°ndolo en una estructura de directorios m√°s mantenible y extensible. Adem√°s, se ha renombrado el proyecto a "MetanoIA".

### Estructura Implementada
Se ha creado la siguiente estructura de directorios:

```
streamlit-apps/
‚îú‚îÄ‚îÄ app.py                  # Nuevo punto de entrada principal
‚îú‚îÄ‚îÄ chat_bot.py             # Versi√≥n original (mantenida como referencia)
‚îú‚îÄ‚îÄ docs/                   # Documentaci√≥n del proyecto
‚îú‚îÄ‚îÄ src/                    # C√≥digo fuente modularizado
‚îÇ   ‚îú‚îÄ‚îÄ api/                # M√≥dulos para interactuar con APIs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_client.py  # Clase base para clientes de API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ groq_client.py  # Cliente para la API de Groq
‚îÇ   ‚îú‚îÄ‚îÄ components/         # Componentes de la interfaz de usuario
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.py         # Componente de chat
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sidebar.py      # Componente de barra lateral
‚îÇ   ‚îú‚îÄ‚îÄ models/             # Configuraci√≥n y gesti√≥n de modelos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_model.py   # Clase base para modelos de lenguaje
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py       # Configuraci√≥n de modelos disponibles
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ groq_models.py  # Implementaciones de modelos de Groq
‚îÇ   ‚îî‚îÄ‚îÄ utils/              # Utilidades generales
‚îÇ       ‚îú‚îÄ‚îÄ env_manager.py  # Gesti√≥n de variables de entorno
‚îÇ       ‚îú‚îÄ‚îÄ logger.py       # Configuraci√≥n del sistema de logging
‚îÇ       ‚îú‚îÄ‚îÄ session_state.py # Gesti√≥n del estado de la sesi√≥n
‚îÇ       ‚îî‚îÄ‚îÄ styles.py       # Estilos y temas de la aplicaci√≥n
‚îî‚îÄ‚îÄ requirements.txt        # Dependencias del proyecto
```

### Mejoras Implementadas

1. **Arquitectura orientada a objetos**:
   - Creaci√≥n de clases base abstractas para facilitar la extensibilidad
   - Implementaci√≥n de interfaces comunes para diferentes proveedores de API
   - Separaci√≥n clara de responsabilidades entre componentes

2. **Mejora de la mantenibilidad**:
   - C√≥digo organizado en m√≥dulos con responsabilidades espec√≠ficas
   - Documentaci√≥n detallada de cada m√≥dulo y funci√≥n
   - Reducci√≥n de la duplicaci√≥n de c√≥digo

3. **Preparaci√≥n para futuras extensiones**:
   - Estructura que facilita la adici√≥n de nuevos modelos de lenguaje
   - Soporte para m√∫ltiples proveedores de API
   - Base para agregar nuevas funcionalidades sin modificar el c√≥digo existente

4. **Cambio de nombre a MetanoIA**:
   - Nombre que refleja mejor la naturaleza del proyecto
   - Actualizaci√≥n de todos los t√≠tulos y referencias en la interfaz
   - Mantenimiento del archivo original `chat_bot.py` como referencia

### C√≥digo Implementado
Se han creado m√∫ltiples archivos nuevos con implementaciones modulares de todas las funcionalidades existentes. Algunos ejemplos clave incluyen:

```python
# Clase base para clientes de API (src/api/base_client.py)
class BaseAPIClient(ABC):
    @abstractmethod
    def is_configured(self):
        pass
    
    @abstractmethod
    def set_api_key(self, api_key):
        pass
    
    @abstractmethod
    def get_cached_response(self, model, messages, temperature, max_tokens):
        pass
    
    @abstractmethod
    def generate_streaming_response(self, model, messages, temperature, max_tokens, callback=None):
        pass
```

```python
# Clase base para modelos de lenguaje (src/models/base_model.py)
class BaseLanguageModel(ABC):
    @property
    @abstractmethod
    def id(self):
        pass
    
    @property
    @abstractmethod
    def display_name(self):
        pass
    
    @property
    @abstractmethod
    def context_length(self):
        pass
    
    @property
    @abstractmethod
    def max_context_messages(self):
        pass
```

### Resultado
- C√≥digo m√°s organizado y mantenible
- Mayor facilidad para extender el proyecto con nuevas funcionalidades
- Mejor separaci√≥n de responsabilidades
- Interfaz de usuario con el nuevo nombre MetanoIA
- Mantenimiento de todas las funcionalidades existentes

## 2025-05-09: Actualizaci√≥n de documentaci√≥n y mejora de la identidad del proyecto

### Tareas Realizadas

1. **Actualizaci√≥n del README.md**:
   - Actualizaci√≥n de la URL del repositorio de GitHub
   - Correcci√≥n del nombre del directorio ra√≠z (de streamlit-apps a MetanoIA)
   - Reorganizaci√≥n de las caracter√≠sticas en categor√≠as m√°s claras
   - Adici√≥n de una secci√≥n sobre la filosof√≠a del proyecto
   - Mejora de la descripci√≥n de la documentaci√≥n disponible

2. **Mejora del grimorio-proyecto.md**:
   - Actualizaci√≥n de la descripci√≥n general del proyecto
   - Adici√≥n de una secci√≥n sobre "La realidad profunda y progresiva sobre MetanoIA"
   - Inclusi√≥n de una nueva secci√≥n sobre "La visi√≥n del asistente en este proyecto"

3. **Creaci√≥n de gu√≠a de integraci√≥n de APIs**:
   - Desarrollo de un documento detallado (`integracion_apis.md`) que explica c√≥mo extender MetanoIA para soportar nuevos proveedores de modelos de lenguaje
   - Inclusi√≥n de ejemplos de c√≥digo completos para la integraci√≥n de Google Gemini
   - Explicaci√≥n de las diferencias entre APIs y consideraciones importantes

4. **Actualizaci√≥n del system prompt predeterminado**:
   - Creaci√≥n de un prompt que refleja la esencia y filosof√≠a del proyecto
   - Explicaci√≥n del significado del nombre "MetanoIA" (Meta + noIA)
   - √ânfasis en el enfoque de aprendizaje progresivo y co-creaci√≥n
   - Inclusi√≥n del enlace al repositorio de GitHub

### Mejoras en la Identidad del Proyecto

1. **Definici√≥n de la filosof√≠a**:
   - Establecimiento de MetanoIA como un viaje de aprendizaje y experimentaci√≥n con la IA
   - √ânfasis en que el proceso de desarrollo es tan valioso como el producto final
   - Promoci√≥n de la comprensi√≥n profunda de los conceptos de programaci√≥n

2. **Personalizaci√≥n de la experiencia del asistente**:
   - Definici√≥n del rol del asistente como un compa√±ero de aprendizaje
   - Establecimiento de una personalidad que promueve la reflexi√≥n cr√≠tica
   - Enfoque en la co-creaci√≥n y el descubrimiento conjunto

### Resultado

La documentaci√≥n del proyecto ahora refleja mejor la visi√≥n y filosof√≠a de MetanoIA, proporcionando una base s√≥lida para el desarrollo futuro y facilitando la contribuci√≥n de otros desarrolladores. El system prompt personalizado establece una identidad clara para el asistente que est√° alineada con los objetivos del proyecto.

## 2025-05-09: Implementaci√≥n de herramientas ag√©nticas

### Tareas Realizadas

1. **Integraci√≥n de modelos compound de Groq**:
   - Implementaci√≥n de soporte para los modelos `compound-beta` y `compound-beta-mini` de Groq
   - Creaci√≥n de clases para representar estos modelos con capacidades ag√©nticas
   - Actualizaci√≥n del sistema de configuraci√≥n para incluir estos modelos en la interfaz

2. **Desarrollo de un gestor de herramientas ag√©nticas**:
   - Creaci√≥n de un sistema para procesar y gestionar los resultados de b√∫squedas web y ejecuciones de c√≥digo
   - Implementaci√≥n de mecanismos para a√±adir esta informaci√≥n al contexto de la conversaci√≥n
   - Desarrollo de un sistema robusto con manejo de excepciones y verificaci√≥n de tipos

3. **Actualizaci√≥n del cliente de Groq**:
   - Modificaci√≥n del cliente para capturar y procesar las herramientas ejecutadas por los modelos ag√©nticos
   - Implementaci√≥n de soporte para el formato de respuesta de los modelos compound
   - Mejora del manejo de errores y logging para facilitar la depuraci√≥n

4. **Integraci√≥n en la interfaz de usuario**:
   - A√±adir opciones en la barra lateral para activar las herramientas ag√©nticas
   - Implementaci√≥n de configuraci√≥n para b√∫squeda web (profundidad, dominios a incluir/excluir)
   - Dise√±o de una experiencia de usuario que mantiene la simplicidad de la interfaz

5. **Documentaci√≥n detallada**:
   - Creaci√≥n de una gu√≠a completa de integraci√≥n de herramientas ag√©nticas
   - Documentaci√≥n de la arquitectura y flujo de trabajo
   - Registro de problemas encontrados y soluciones implementadas

### Problemas Encontrados y Soluciones

1. **Error de importaci√≥n**:
   - Problema: Falta de importaci√≥n de la funci√≥n `display_agentic_context` en el archivo principal
   - Soluci√≥n: A√±adir la importaci√≥n correcta en `app.py`

2. **Error en el procesamiento de herramientas ag√©nticas**:
   - Problema: El m√©todo `process_executed_tools` fallaba cuando el campo "output" era un string en lugar de un diccionario
   - Soluci√≥n: Implementar verificaci√≥n de tipos y manejo de excepciones para procesar correctamente diferentes formatos de respuesta

3. **Interfaz sobrecargada**:
   - Problema: La visualizaci√≥n de resultados de b√∫squeda en la interfaz resultaba redundante
   - Soluci√≥n: Eliminar la secci√≥n de resultados de b√∫squeda en la interfaz, manteniendo la funcionalidad de a√±adir la informaci√≥n al contexto

### C√≥digo Implementado

```python
# Definici√≥n de modelos ag√©nticos (src/models/agentic_models.py)
class CompoundBetaModel(BaseLanguageModel):
    """Modelo Compound Beta de Groq con capacidades ag√©nticas."""
    
    def __init__(self):
        self._id = "compound-beta"
        self._display_name = "Compound Beta (Ag√©ntico)"
    
    @property
    def is_agentic(self):
        return True
    
    @property
    def supports_multiple_tools(self):
        return True
```

```python
# Procesamiento robusto de herramientas ag√©nticas (src/utils/agentic_tools_manager.py)
def process_executed_tools(self, executed_tools):
    for tool in executed_tools:
        try:
            # Verificar que tool sea un diccionario
            if not isinstance(tool, dict):
                logger.warning(f"Herramienta no es un diccionario: {tool}")
                continue
            
            # Obtener input y output de forma segura
            tool_input = tool.get("input", {})
            tool_output = tool.get("output", {})
            
            # Convertir a diccionario si son strings
            if isinstance(tool_input, str):
                tool_input = {"raw": tool_input}
            
            if isinstance(tool_output, str):
                tool_output = {"raw": tool_output}
            
            # Procesar seg√∫n el tipo de herramienta
            # ...
        except Exception as e:
            logger.error(f"Error al procesar herramienta: {str(e)}")
            continue
```

### Resultado

MetanoIA ahora cuenta con capacidades ag√©nticas que le permiten:

- Buscar informaci√≥n en internet en tiempo real usando los modelos compound de Groq
- Ejecutar c√≥digo Python para realizar c√°lculos o generar visualizaciones
- Incorporar autom√°ticamente los resultados de estas herramientas al contexto de la conversaci√≥n
- Mantener una interfaz limpia y centrada en la conversaci√≥n, donde el modelo puede citar directamente las fuentes en sus respuestas

Esta implementaci√≥n mejora significativamente las capacidades del asistente, permiti√©ndole acceder a informaci√≥n actualizada y realizar tareas complejas, lo que resulta en respuestas m√°s precisas y √∫tiles para el usuario.

## 2025-05-10: Implementaci√≥n de capacidades de visi√≥n

### Tareas Realizadas

1. **Extensi√≥n de la arquitectura base**:
   - Actualizaci√≥n de la clase base `BaseAPIClient` para a√±adir el m√©todo abstracto `generate_response_with_image`
   - Implementaci√≥n de este m√©todo en `GroqClient` para procesar im√°genes con modelos multimodales
   - Actualizaci√≥n de la clase base `BaseLanguageModel` con la propiedad `supports_vision`

2. **Implementaci√≥n del procesador de im√°genes**:
   - Creaci√≥n del m√≥dulo `image_processor.py` con funciones para redimensionar, validar y codificar im√°genes
   - Implementaci√≥n de l√≠mites de tama√±o y resoluci√≥n seg√∫n las restricciones de Groq (33MP, 4MB m√°ximo)
   - Optimizaci√≥n autom√°tica de im√°genes mediante redimensionamiento y compresi√≥n

3. **Actualizaci√≥n del estado de sesi√≥n**:
   - Ampliaci√≥n del estado de sesi√≥n para almacenar el contexto de im√°genes
   - Implementaci√≥n de un sistema para mantener un historial limitado de im√°genes recientes
   - Almacenamiento de descripciones generadas para facilitar referencias futuras

4. **Integraci√≥n en la interfaz de usuario**:
   - Actualizaci√≥n del sidebar para mostrar opciones de visi√≥n cuando se selecciona un modelo compatible
   - Implementaci√≥n de carga de im√°genes con previsualizaci√≥n
   - Botones para acciones r√°pidas (describir imagen, extraer texto)

5. **Actualizaci√≥n del componente de chat**:
   - Modificaci√≥n de `handle_user_input` para detectar y procesar im√°genes pendientes
   - Integraci√≥n con el contexto de la conversaci√≥n para mantener la coherencia
   - Mejora del manejo de errores y registro detallado

6. **Documentaci√≥n completa**:
   - Actualizaci√≥n de `integracion_vision.md` para reflejar la implementaci√≥n realizada
   - Documentaci√≥n de limitaciones t√©cnicas y consideraciones de uso
   - Planificaci√≥n de mejoras futuras (integraci√≥n con OpenAI y otros proveedores)

### C√≥digo Implementado

```python
# Extensi√≥n de la clase base (src/api/base_client.py)
@abstractmethod
def generate_response_with_image(self, model, messages, image_data, temperature, max_tokens, callback=None):
    """
    Genera una respuesta basada en texto e imagen.
    
    Args:
        model (str): ID del modelo a utilizar.
        messages (list): Lista de mensajes para la conversaci√≥n.
        image_data (dict): Datos de la imagen (URL o base64).
        temperature (float): Temperatura para la generaci√≥n.
        max_tokens (int): N√∫mero m√°ximo de tokens en la respuesta.
        callback (callable, optional): Funci√≥n de callback para cada fragmento de respuesta.
        
    Returns:
        dict: Diccionario con la respuesta completa generada y metadatos.
    """
    pass
```

```python
# Procesamiento de im√°genes (src/utils/image_processor.py)
def resize_image(image_path, max_pixels=33177600, max_size_mb=4):
    """
    Redimensiona una imagen si excede el n√∫mero m√°ximo de p√≠xeles o tama√±o.
    """
    # Implementaci√≥n que garantiza que las im√°genes cumplan con los l√≠mites de Groq
    # Redimensionamiento inteligente y compresi√≥n progresiva
```

```python
# Integraci√≥n en el sidebar (src/components/sidebar.py)
# Configuraci√≥n de procesamiento de im√°genes
if supports_vision:
    st.info("Has seleccionado un modelo con capacidades de visi√≥n que puede analizar im√°genes.")
    
    # Activar/desactivar visi√≥n
    enable_vision = st.checkbox(
        "Activar procesamiento de im√°genes",
        value=session_state.context.get("enable_vision", False),
        help="Permite que el modelo analice im√°genes y extraiga informaci√≥n de ellas."
    )
    
    # Opciones de procesamiento de im√°genes
    if enable_vision:
        st.subheader("Procesamiento de Im√°genes")
        uploaded_file = st.file_uploader("Cargar imagen", type=["jpg", "jpeg", "png"])
        # Implementaci√≥n de carga y procesamiento de im√°genes
```

### Problemas Encontrados y Soluciones

1. **Limitaciones de tama√±o de im√°genes**:
   - Problema: Las im√°genes grandes causaban errores en la API de Groq (l√≠mite de 4MB para base64)
   - Soluci√≥n: Implementaci√≥n de redimensionamiento y compresi√≥n autom√°tica con calidad progresiva

2. **Integraci√≥n con modelos espec√≠ficos**:
   - Problema: Solo los modelos Meta Llama 4 Scout y Maverick soportan capacidades de visi√≥n
   - Soluci√≥n: Implementaci√≥n de la propiedad `supports_vision` y verificaci√≥n din√°mica en la interfaz

3. **Gesti√≥n del contexto de im√°genes**:
   - Problema: Necesidad de mantener el contexto de im√°genes entre mensajes
   - Soluci√≥n: Extensi√≥n del estado de sesi√≥n con un sistema de seguimiento de im√°genes procesadas

### Resultado

MetanoIA ahora cuenta con capacidades de visi√≥n que le permiten:

- Analizar y describir im√°genes subidas por el usuario
- Extraer texto de im√°genes mediante OCR
- Responder preguntas espec√≠ficas sobre el contenido visual
- Mantener el contexto visual a lo largo de la conversaci√≥n

Esta implementaci√≥n enriquece significativamente la experiencia del usuario, permitiendo una interacci√≥n m√°s natural y completa con el asistente. Adem√°s, mantiene el enfoque educativo del proyecto, sirviendo como ejemplo pr√°ctico de integraci√≥n de tecnolog√≠as multimodales en aplicaciones de IA conversacional.

## 2025-05-11: Integraci√≥n de Speech-to-Text (Voz a Texto)

### Tarea Realizada
Se ha implementado la funcionalidad de transcripci√≥n de voz a texto utilizando la API de Groq, permitiendo a los usuarios subir archivos de audio para transcribirlos y utilizarlos como entrada en la conversaci√≥n con el asistente.

### Componentes Implementados

1. **Interfaz de usuario para audio** (`src/components/audio.py`):
   - Implementaci√≥n de un componente para subir archivos de audio
   - Opciones para seleccionar el modelo de transcripci√≥n y el idioma
   - Reproducci√≥n del audio subido para verificaci√≥n

2. **Servicio de transcripci√≥n** (`src/api/audio_transcription.py`):
   - Clase `AudioTranscriber` que utiliza la API de Groq para transcribir audio
   - Soporte para diferentes modelos de Whisper (whisper-large-v3-turbo, whisper-large-v3, distil-whisper-large-v3-en)
   - Manejo de errores y registro detallado del proceso

3. **Integraci√≥n con el flujo de conversaci√≥n**:
   - Modificaci√≥n de `handle_user_input` para procesar transcripciones de audio
   - Gesti√≥n de archivos temporales y limpieza autom√°tica
   - Incorporaci√≥n del texto transcrito como mensaje del usuario

4. **Documentaci√≥n completa** (`docs/integracion_speech_to_text.md`):
   - Explicaci√≥n detallada de la arquitectura y funcionamiento
   - Descripci√≥n de los modelos disponibles y sus caracter√≠sticas
   - Limitaciones t√©cnicas y consideraciones de uso
   - Posibles mejoras futuras

### C√≥digo Implementado

```python
# Componente de audio (src/components/audio.py)
def display_audio_input(session_state):
    """
    Muestra los controles para subir o grabar audio y transcribirlo.
    """
    audio_data = None
    
    # Crear un expander para los controles de audio
    with st.expander("üé§ Entrada de voz", expanded=False):
        # Implementaci√≥n de la interfaz para subir archivos de audio
        # y configurar opciones de transcripci√≥n
```

```python
# Servicio de transcripci√≥n (src/api/audio_transcription.py)
class AudioTranscriber:
    """
    Clase para manejar la transcripci√≥n de audio utilizando la API de Groq.
    """
    def transcribe_audio(self, audio_path, model="whisper-large-v3-turbo", language=None, response_format="text"):
        """
        Transcribe un archivo de audio utilizando la API de Groq.
        """
        # Implementaci√≥n de la comunicaci√≥n con la API de Groq
        # y procesamiento de resultados
```

```python
# Integraci√≥n en app.py
# Procesar entrada de audio si est√° habilitada
audio_data = display_audio_input(session_state)
if audio_data:
    # Mostrar mensaje de procesamiento
    with st.spinner(f"Transcribiendo audio con {audio_data['model']}..."):
        # Inicializar el transcriptor de audio
        transcriber = AudioTranscriber(groq_client, logger)
        
        # Transcribir el audio
        result = transcriber.transcribe_audio(
            audio_path=audio_data['path'],
            model=audio_data['model'],
            language=audio_data['language']
        )
```

### Problemas Encontrados y Soluciones

1. **Limitaci√≥n de Streamlit**:
   - Problema: La versi√≥n actual de Streamlit no incluye el componente `st.audio_recorder()` para grabaci√≥n directa
   - Soluci√≥n: Implementaci√≥n centrada en la subida de archivos de audio con instrucciones alternativas para grabaci√≥n

2. **Manejo de archivos temporales**:
   - Problema: Necesidad de gestionar los archivos de audio subidos temporalmente
   - Soluci√≥n: Implementaci√≥n de un sistema de limpieza autom√°tica de archivos temporales

### Resultado

MetanoIA ahora cuenta con capacidades de procesamiento de voz que le permiten:

- Transcribir archivos de audio en m√∫ltiples formatos
- Utilizar diferentes modelos de Whisper seg√∫n las necesidades
- Incorporar el texto transcrito directamente en la conversaci√≥n
- Mantener un flujo de trabajo educativo donde el usuario comprende cada parte del proceso

Esta integraci√≥n complementa las capacidades multimodales del proyecto, a√±adiendo una nueva dimensi√≥n de interacci√≥n que enriquece la experiencia del usuario y sirve como ejemplo pr√°ctico de c√≥mo las tecnolog√≠as de IA pueden trabajar juntas en un sistema integrado.
