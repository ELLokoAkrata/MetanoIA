# Integraci√≥n de Procesamiento de Archivos en MetanoIA

## Introducci√≥n

Este documento describe la implementaci√≥n de capacidades de procesamiento de archivos en MetanoIA, extendiendo las funcionalidades existentes de generaci√≥n de archivos. Esta integraci√≥n permite que el sistema no solo genere archivos en diferentes formatos, sino que tambi√©n pueda leer, analizar y transformar archivos subidos por el usuario.

## Objetivos

1. Mantener la coherencia con la filosof√≠a educativa de MetanoIA
2. Integrar el procesamiento de archivos con el flujo actual de generaci√≥n
3. Soportar los mismos formatos que ya se pueden generar (JSON, Python, Markdown, TXT, CSV, HTML, CSS, JS, Excel)
4. Implementar una l√≥gica centralizada y sin redundancias
5. Manejar eficientemente archivos de diferentes tama√±os

## Arquitectura Propuesta

### 1. Extensi√≥n del Sistema Actual

La arquitectura actual de generaci√≥n de archivos se basa en:
- `FileGenerator` en `src/api/file_generator.py` (backend)
- Componentes de UI en `src/components/file_generator.py` (frontend)

Proponemos extender este sistema manteniendo la misma estructura modular:

```
src/
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ file_generator.py     ‚Üí A√±adir m√©todos de procesamiento
‚îÇ   ‚îî‚îÄ‚îÄ file_processor.py     ‚Üí Nuevo m√≥dulo para procesamiento espec√≠fico
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ file_generator.py     ‚Üí Extender para incluir UI de procesamiento
‚îÇ   ‚îî‚îÄ‚îÄ file_processor.py     ‚Üí Nuevo componente para UI de procesamiento
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ file_utils.py         ‚Üí Funciones auxiliares compartidas
```

### 2. Modelo de Datos y Flujo

#### Flujo de Procesamiento

1. **Subida de archivo**: El usuario sube un archivo a trav√©s de la interfaz
2. **Detecci√≥n de tipo**: El sistema detecta autom√°ticamente el tipo de archivo
3. **An√°lisis preliminar**: Se realiza un an√°lisis inicial del contenido y estructura
4. **Procesamiento por LLM**: El modelo de lenguaje analiza el archivo y sugiere transformaciones
5. **Transformaci√≥n**: Se aplican las transformaciones sugeridas
6. **Visualizaci√≥n**: Se muestra una comparaci√≥n entre el archivo original y el procesado
7. **Descarga**: El usuario puede descargar el archivo procesado

#### Integraci√≥n con el Flujo Actual

```mermaid
graph TD
    A[Usuario] -->|Sube archivo| B[Interfaz de Subida]
    A -->|Solicita generaci√≥n| C[Interfaz de Generaci√≥n]
    
    B -->|Detecta tipo| D[FileProcessor]
    C -->|Genera contenido| E[FileGenerator]
    
    D -->|Analiza| F[LLM]
    E -->|Genera| F
    
    F -->|Devuelve an√°lisis/contenido| G[Transformador de Archivos]
    
    G -->|Archivo procesado| H[Visualizador de Comparaci√≥n]
    G -->|Archivo generado| I[Visualizador de Archivo]
    
    H -->|Descarga| J[Usuario]
    I -->|Descarga| J
```

## Estado Actual de la Implementaci√≥n

Actualmente, la implementaci√≥n del procesamiento de archivos en MetanoIA incluye:

### Componentes Implementados

1. **Estructura base**:
   - M√≥dulo `file_processor.py` en `src/api/` para el procesamiento de archivos
   - Componente UI `file_processor.py` en `src/components/` para la interfaz de usuario
   - Utilidades en `file_utils.py` para operaciones comunes sobre archivos

2. **Integraci√≥n con la aplicaci√≥n principal**:
   - El componente de procesamiento de archivos est√° integrado en `app.py`
   - La gesti√≥n del estado de sesi√≥n incluye inicializaci√≥n y limpieza de archivos procesados

3. **Formatos de archivo soportados**:
   - Texto (TXT): Lectura y procesamiento b√°sico
   - JSON: Lectura y conversi√≥n a diccionario
   - PDF: Extracci√≥n de texto (requiere PyPDF2)

4. **Funcionalidades de procesamiento**:
   - Divisi√≥n de texto en fragmentos manejables por tokens
   - Generaci√≥n de res√∫menes para textos extensos
   - Detecci√≥n autom√°tica de tipos de archivo

### Pendiente de Implementaci√≥n

1. **Procesadores espec√≠ficos avanzados**:
   - Procesamiento avanzado de CSV con opciones de filtrado y transformaci√≥n
   - Procesamiento de Excel con soporte para m√∫ltiples hojas
   - Procesamiento de c√≥digo (Python, HTML, CSS, JS) con an√°lisis y formateo

2. **Integraci√≥n con LLM**:
   - An√°lisis inteligente de archivos usando modelos de lenguaje
   - Sugerencias autom√°ticas de procesamiento
   - Transformaciones basadas en instrucciones en lenguaje natural

3. **Visualizaci√≥n mejorada**:
   - Componente de comparaci√≥n entre archivo original y procesado
   - Visualizaci√≥n interactiva para diferentes tipos de archivo

4. **Optimizaciones**:
   - Manejo eficiente de archivos grandes
   - Procesamiento por fragmentos para archivos extensos
   - Indicadores de progreso para operaciones largas

## Implementaci√≥n T√©cnica

### 1. Extensi√≥n de `FileGenerator`

A√±adir m√©todos para procesar archivos existentes:

```python
def process_file(self, file_content: Any, file_type: str, processing_options: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    Procesa un archivo existente seg√∫n su tipo y opciones especificadas.
    
    Args:
        file_content: Contenido del archivo a procesar.
        file_type: Tipo de archivo (json, python, markdown, etc.).
        processing_options: Opciones espec√≠ficas para el procesamiento.
        
    Returns:
        Dict[str, Any]: Informaci√≥n del archivo procesado.
    """
    # Verificar que el tipo de archivo est√© soportado
    if file_type not in FILE_TYPES:
        error_msg = f"Tipo de archivo no soportado para procesamiento: {file_type}"
        if self.logger:
            self.logger.error(error_msg)
        return {"success": False, "error": error_msg}
    
    # Procesar seg√∫n el tipo de archivo
    try:
        processed_content = None
        
        if file_type == 'json':
            processed_content = self._process_json_file(file_content, processing_options)
        elif file_type == 'csv':
            processed_content = self._process_csv_file(file_content, processing_options)
        # ... otros tipos
        
        # Generar archivo con el contenido procesado
        result = self.generate_file(processed_content, f"processed_{datetime.now().strftime('%Y%m%d%H%M%S')}", file_type)
        
        # A√±adir metadatos de procesamiento
        result["original_content"] = file_content
        result["processing_options"] = processing_options
        
        return result
        
    except Exception as e:
        error_msg = f"Error al procesar archivo {file_type}: {str(e)}"
        if self.logger:
            self.logger.error(error_msg)
            self.logger.exception("Detalles del error:")
        
        return {
            "success": False,
            "error": error_msg
        }
```

### 2. Manejo de Archivos Grandes

Para archivos grandes, implementaremos:

1. **Procesamiento por fragmentos**:
   - Dividir archivos grandes en fragmentos manejables
   - Procesar cada fragmento por separado
   - Combinar los resultados

2. **Streaming de archivos**:
   - Usar `io.StringIO` o `io.BytesIO` para archivos en memoria
   - Implementar procesamiento en streaming para CSV y otros formatos tabulares

```python
def _process_large_file(self, file_path: str, chunk_size: int = 1024*1024, 
                        processor_func: callable = None) -> Any:
    """
    Procesa un archivo grande por fragmentos.
    
    Args:
        file_path: Ruta al archivo a procesar.
        chunk_size: Tama√±o de cada fragmento en bytes.
        processor_func: Funci√≥n para procesar cada fragmento.
        
    Returns:
        Any: Resultado combinado del procesamiento.
    """
    results = []
    
    with open(file_path, 'rb') as f:
        while True:
            chunk = f.read(chunk_size)
            if not chunk:
                break
                
            # Procesar el fragmento
            if processor_func:
                result = processor_func(chunk)
                results.append(result)
    
    # Combinar resultados
    return self._combine_results(results)
```

### 3. Procesadores Espec√≠ficos por Tipo de Archivo

Implementaremos procesadores espec√≠ficos para cada tipo de archivo soportado:

#### JSON

```python
def _process_json_file(self, content: Dict[str, Any], options: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    Procesa un archivo JSON.
    
    Operaciones posibles:
    - Formateo y embellecimiento
    - Filtrado de campos
    - Transformaci√≥n de valores
    - Validaci√≥n contra esquema
    """
    options = options or {}
    
    # Formatear JSON
    if options.get('format', True):
        # Ya est√° en formato de diccionario, no necesita parsing
        pass
        
    # Filtrar campos
    if 'filter_fields' in options:
        content = self._filter_json_fields(content, options['filter_fields'])
        
    # Transformar valores
    if 'transformations' in options:
        content = self._transform_json_values(content, options['transformations'])
        
    # Validar contra esquema
    if 'schema' in options:
        self._validate_json_schema(content, options['schema'])
        
    return content
```

#### CSV

```python
def _process_csv_file(self, content: List[List[Any]], options: Dict[str, Any] = None) -> List[List[Any]]:
    """
    Procesa un archivo CSV.
    
    Operaciones posibles:
    - Filtrado de filas/columnas
    - Transformaci√≥n de valores
    - Agregaci√≥n de datos
    - Ordenamiento
    """
    options = options or {}
    
    # Convertir a DataFrame para facilitar el procesamiento
    import pandas as pd
    
    # Determinar si es una lista de listas o una lista de diccionarios
    if content and isinstance(content[0], dict):
        df = pd.DataFrame(content)
    else:
        df = pd.DataFrame(content[1:], columns=content[0] if content else None)
    
    # Filtrar filas
    if 'filter_rows' in options:
        query = options['filter_rows']
        df = df.query(query) if query else df
    
    # Filtrar columnas
    if 'select_columns' in options:
        columns = options['select_columns']
        df = df[columns] if columns else df
    
    # Ordenar
    if 'sort_by' in options:
        sort_by = options['sort_by']
        ascending = options.get('ascending', True)
        df = df.sort_values(by=sort_by, ascending=ascending)
    
    # Transformar a formato original
    if content and isinstance(content[0], dict):
        return df.to_dict('records')
    else:
        return [df.columns.tolist()] + df.values.tolist()
```

### 4. Componente de UI para Procesamiento

Extenderemos la interfaz de usuario para incluir opciones de procesamiento:

```python
def display_file_processor():
    """
    Muestra la interfaz para procesar archivos.
    """
    st.subheader("Procesador de Archivos")
    
    uploaded_file = st.file_uploader("Subir archivo para procesar", 
                                    type=["json", "csv", "txt", "md", "py", "html", "css", "js", "xlsx"])
    
    if uploaded_file is not None:
        # Detectar tipo de archivo
        file_type = detect_file_type(uploaded_file)
        
        st.info(f"Archivo detectado: {uploaded_file.name} (Tipo: {file_type})")
        
        # Mostrar opciones espec√≠ficas seg√∫n el tipo de archivo
        processing_options = {}
        
        if file_type == "json":
            st.subheader("Opciones de procesamiento JSON")
            processing_options["format"] = st.checkbox("Formatear JSON", value=True)
            processing_options["filter_fields"] = st.text_input("Campos a incluir (separados por coma)")
            
        elif file_type == "csv":
            st.subheader("Opciones de procesamiento CSV")
            processing_options["filter_rows"] = st.text_input("Filtro de filas (expresi√≥n)")
            processing_options["select_columns"] = st.text_input("Columnas a incluir (separadas por coma)")
            processing_options["sort_by"] = st.text_input("Ordenar por columna")
            
        # ... opciones para otros tipos de archivo
        
        # Bot√≥n para procesar
        if st.button("Procesar archivo"):
            with st.spinner("Procesando archivo..."):
                # Leer contenido del archivo
                file_content = read_file_content(uploaded_file, file_type)
                
                # Procesar archivo
                result = file_processor.process_file(file_content, file_type, processing_options)
                
                if result.get("success", False):
                    # Mostrar comparaci√≥n
                    display_file_comparison(result["original_content"], result["processed_content"], file_type)
                    
                    # Mostrar bot√≥n de descarga
                    display_file_download(result)
                else:
                    st.error(f"Error al procesar el archivo: {result.get('error', 'Error desconocido')}")
```

### 5. Visualizaci√≥n de Comparaci√≥n

Implementaremos un componente para comparar el archivo original con el procesado:

```python
def display_file_comparison(original_content, processed_content, file_type):
    """
    Muestra una comparaci√≥n entre el contenido original y el procesado.
    """
    st.subheader("Comparaci√≥n")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Archivo Original**")
        display_content_preview(original_content, file_type)
        
    with col2:
        st.markdown("**Archivo Procesado**")
        display_content_preview(processed_content, file_type)
```

## Manejo de Errores y Seguridad

### Validaci√≥n de Archivos

Implementaremos validaciones de seguridad para los archivos subidos:

1. **Verificaci√≥n de tama√±o**: Limitar el tama√±o m√°ximo de los archivos
2. **Validaci√≥n de contenido**: Verificar que el contenido corresponda al tipo declarado
3. **Sanitizaci√≥n**: Eliminar contenido potencialmente peligroso

```python
def validate_uploaded_file(uploaded_file, max_size_mb=20):
    """
    Valida que un archivo subido cumpla con los requisitos de seguridad.
    
    Args:
        uploaded_file: Archivo subido por el usuario.
        max_size_mb: Tama√±o m√°ximo permitido en MB.
        
    Returns:
        tuple: (bool, str) - Validez y mensaje de error si aplica.
    """
    try:
        # Verificar que el archivo existe
        if uploaded_file is None:
            return False, "No se ha subido ning√∫n archivo"
        
        # Verificar el tama√±o
        file_size_mb = uploaded_file.size / (1024 * 1024)
        if file_size_mb > max_size_mb:
            return False, f"El archivo es demasiado grande: {file_size_mb:.2f}MB (m√°ximo {max_size_mb}MB)"
        
        # Verificar el tipo de archivo
        file_type = detect_file_type(uploaded_file)
        if file_type not in FILE_TYPES:
            return False, f"Tipo de archivo no soportado: {file_type}"
        
        # Validar el contenido seg√∫n el tipo
        is_valid, error_msg = validate_file_content(uploaded_file, file_type)
        if not is_valid:
            return False, error_msg
        
        return True, ""
        
    except Exception as e:
        logger.error(f"Error al validar el archivo: {str(e)}")
        logger.exception("Detalles del error:")
        return False, f"Error al validar el archivo: {str(e)}"
```

## Integraci√≥n con el Sistema de Manejo de Contexto

Una caracter√≠stica fundamental de MetanoIA es su capacidad para mantener el contexto de la conversaci√≥n independientemente del modelo de lenguaje que se est√© utilizando. Para integrar el procesamiento de archivos con este sistema, debemos asegurar que la informaci√≥n del archivo procesado se mantenga disponible en el contexto incluso cuando el usuario cambie de modelo.

### Arquitectura de Manejo de Contexto

El sistema actual de manejo de contexto en MetanoIA se basa en:

1. **Almacenamiento centralizado de mensajes**: Todos los mensajes se almacenan en una estructura com√∫n accesible por cualquier modelo.
2. **Serializaci√≥n y deserializaci√≥n de mensajes**: Los mensajes se convierten a un formato com√∫n que puede ser interpretado por cualquier modelo.
3. **Gesti√≥n de estado de sesi√≥n**: El estado de la sesi√≥n se mantiene independientemente del modelo activo.

### Integraci√≥n del Procesamiento de Archivos en el Contexto

```python
def add_file_to_context(self, file_info: Dict[str, Any], conversation_context: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    A√±ade la informaci√≥n de un archivo procesado al contexto de la conversaci√≥n.
    
    Args:
        file_info: Informaci√≥n del archivo procesado.
        conversation_context: Contexto actual de la conversaci√≥n.
        
    Returns:
        List[Dict[str, Any]]: Contexto actualizado.
    """
    # Crear un resumen del archivo para el contexto
    file_summary = {
        "type": "file_summary",
        "file_name": file_info.get("filename", "archivo_sin_nombre"),
        "file_type": file_info.get("file_type", "desconocido"),
        "content_summary": self._generate_file_summary(file_info),
        "timestamp": datetime.now().isoformat(),
        "file_id": file_info.get("file_id", str(uuid.uuid4()))
    }
    
    # A√±adir el resumen como un mensaje del sistema en el contexto
    system_message = {
        "role": "system",
        "content": f"El usuario ha procesado un archivo: {file_summary['file_name']} (tipo: {file_summary['file_type']}). "
                  f"Resumen del contenido: {file_summary['content_summary']}"
    }
    
    # Almacenar los detalles completos en el estado de la sesi√≥n
    st.session_state.processed_files = st.session_state.get("processed_files", {})
    st.session_state.processed_files[file_summary["file_id"]] = file_info
    
    # A√±adir el mensaje al contexto
    conversation_context.append(system_message)
    
    return conversation_context

def _generate_file_summary(self, file_info: Dict[str, Any]) -> str:
    """
    Genera un resumen del contenido del archivo para incluir en el contexto.
    
    Args:
        file_info: Informaci√≥n del archivo procesado.
        
    Returns:
        str: Resumen del contenido del archivo.
    """
    file_type = file_info.get("file_type", "")
    content = file_info.get("content", None)
    
    if content is None:
        return "Contenido no disponible"
    
    # Generar resumen seg√∫n el tipo de archivo
    if file_type == "json":
        return self._summarize_json(content)
    elif file_type == "csv":
        return self._summarize_csv(content)
    elif file_type == "txt" or file_type == "md":
        return self._summarize_text(content)
    # ... otros tipos
    
    return "Resumen no disponible para este tipo de archivo"
```

### Recomendaciones de Modelos para Procesamiento de Archivos

Cada tipo de archivo puede beneficiarse de diferentes capacidades de los modelos disponibles:

| Tipo de Archivo | Modelo Recomendado | Raz√≥n |
|-----------------|-------------------|-------|
| JSON            | Llama-3-70b       | Mejor comprensi√≥n de estructuras de datos complejas |
| CSV             | Claude-3-Opus     | Excelente para an√°lisis tabular y estad√≠stico |
| C√≥digo (Python, JS) | Llama-3-70b    | Mejor comprensi√≥n de sintaxis y patrones de c√≥digo |
| Texto (TXT, MD) | Cualquiera        | Todos los modelos son adecuados para texto plano |
| Excel           | Claude-3-Opus     | Mejor para an√°lisis de datos estructurados |

### Persistencia del Contexto al Cambiar de Modelo

Para asegurar que la informaci√≥n del archivo procesado se mantenga disponible al cambiar de modelo, implementaremos:

```python
def preserve_file_context_on_model_change(self, new_model: str) -> None:
    """
    Preserva el contexto de los archivos procesados al cambiar de modelo.
    
    Args:
        new_model: Nombre del nuevo modelo al que se est√° cambiando.
    """
    # Verificar si hay archivos procesados en la sesi√≥n
    if "processed_files" not in st.session_state:
        return
    
    # Obtener el contexto actual
    current_context = st.session_state.get("messages", [])
    
    # Verificar si necesitamos regenerar los res√∫menes para el nuevo modelo
    if new_model in ["claude-3-opus", "claude-3-sonnet"]:
        # Formato espec√≠fico para modelos Claude
        for file_id, file_info in st.session_state.processed_files.items():
            # Encontrar y actualizar los mensajes del sistema relacionados con este archivo
            for i, msg in enumerate(current_context):
                if msg.get("role") == "system" and f"file_id: {file_id}" in msg.get("content", ""):
                    # Actualizar el formato para Claude
                    current_context[i] = self._format_file_message_for_claude(file_info)
    
    # Actualizar el contexto en la sesi√≥n
    st.session_state.messages = current_context
```

## Integraci√≥n con el Sistema de Herramientas

Para integrar con el sistema actual de herramientas de Groq, a√±adiremos definiciones para el procesamiento de archivos:

```python
def get_file_processing_tools_definitions(self) -> List[Dict[str, Any]]:
    """
    Obtiene las definiciones de herramientas para el procesamiento de archivos.
    
    Returns:
        List[Dict[str, Any]]: Lista de definiciones de herramientas.
    """
    tools = []
    
    # Generar definiciones para cada tipo de archivo soportado
    for file_type, config in FILE_TYPES.items():
        # Omitir tipos que requieren bibliotecas no disponibles
        if config.get('requires_library') and config['requires_library'] not in self.available_libraries:
            continue
            
        # Crear la definici√≥n de la herramienta
        tool = {
            "type": "function",
            "function": {
                "name": f"process_{file_type}_file",
                "description": f"Procesa un archivo {file_type.upper()} ({config['extension']}) subido por el usuario",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "processing_options": {
                            "type": "object",
                            "description": f"Opciones para el procesamiento del archivo {file_type}"
                        }
                    },
                    "required": []
                }
            }
        }
        
        tools.append(tool)
    
    return tools
```

## Plan de Implementaci√≥n

### Fase 1: Estructura Base ‚úÖ

1. ‚úÖ Crear el nuevo m√≥dulo `file_processor.py` en `src/api/`
2. ‚úÖ Implementar funciones b√°sicas de procesamiento de archivos
3. ‚úÖ Implementar la detecci√≥n autom√°tica de tipos de archivo
4. ‚úÖ Crear la interfaz b√°sica para subida y procesamiento
5. ‚úÖ Integrar con el sistema de gesti√≥n de estado de sesi√≥n

### Fase 2: Procesadores Espec√≠ficos üîÑ

1. ‚úÖ Implementar procesadores b√°sicos para TXT, JSON y PDF
2. ‚è≥ Implementar procesador avanzado para CSV con opciones de filtrado
3. ‚è≥ Desarrollar el componente de visualizaci√≥n de comparaci√≥n
4. ‚è≥ Implementar validaciones de seguridad avanzadas

### Fase 3: Manejo de Archivos Grandes ‚è≥

1. ‚úÖ Implementar divisi√≥n de texto en fragmentos por tokens
2. ‚è≥ A√±adir soporte para streaming de archivos
3. ‚è≥ Optimizar el rendimiento para archivos grandes
4. ‚è≥ Implementar indicadores de progreso

### Fase 4: Integraci√≥n con LLM ‚è≥

1. ‚è≥ Extender el sistema de herramientas de Groq para procesamiento
2. ‚è≥ Implementar an√°lisis inteligente de archivos
3. ‚è≥ A√±adir sugerencias autom√°ticas de procesamiento
4. ‚è≥ Integrar con el historial de conversaci√≥n

**Leyenda:**
- ‚úÖ Completado
- üîÑ En progreso
- ‚è≥ Pendiente

## Consideraciones Educativas

Siguiendo la filosof√≠a de MetanoIA, esta implementaci√≥n debe:

1. **Explicar cada paso**: Mostrar al usuario qu√© transformaciones se est√°n aplicando
2. **Ser transparente**: Permitir ver el c√≥digo generado para las transformaciones
3. **Ser did√°ctica**: Incluir comentarios y explicaciones en el c√≥digo generado
4. **Ser progresiva**: Permitir diferentes niveles de complejidad seg√∫n la experiencia del usuario

## Conclusi√≥n

La integraci√≥n del procesamiento de archivos en MetanoIA ha avanzado significativamente, con la implementaci√≥n completa de la estructura base y la integraci√≥n en la aplicaci√≥n principal. El sistema actual permite:

1. **Subir y procesar archivos** a trav√©s de una interfaz de usuario integrada en la aplicaci√≥n principal
2. **Manejar formatos b√°sicos** (TXT, JSON, PDF) con funcionalidades de lectura y procesamiento
3. **Mantener la coherencia** con la filosof√≠a educativa de MetanoIA
4. **Gestionar eficientemente** los archivos temporales durante la sesi√≥n

El enfoque modular y extensible implementado facilitar√° la adici√≥n de soporte para m√°s tipos de archivo y operaciones de procesamiento en el futuro. Las pr√≥ximas fases de desarrollo se centrar√°n en:

- Ampliar los procesadores espec√≠ficos para formatos adicionales
- Mejorar el manejo de archivos grandes
- Integrar capacidades avanzadas de an√°lisis con modelos de lenguaje
- Desarrollar visualizaciones interactivas para diferentes tipos de archivo

Esta implementaci√≥n sigue las mejores pr√°cticas de programaci√≥n y se integra perfectamente con el flujo actual de generaci√≥n de archivos, proporcionando una experiencia unificada y educativa al usuario.
